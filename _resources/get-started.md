---
layout: default

# text to show on the card
display-title: Get Started  
details: Get started with an introduction to major concepts in bias and AI/ML.

# whether or not the card is "featured" on the /resources page or homepage
featured: true

# pills above the title on the card
tags:
  - Primer

---

# Getting Started

## Overview
Bias is the systematic favoring or disfavoring of a specific group of people relative to another group. Bias can arise in every step of the decision-making process--for data driven decisions, the process by which you collect and treat data may introduce bias. The decision-making frameworks themselves, often driven by artificial intelligence or machine learning algorithms, can also be constructed in a way that introduces bias. The effects of bias can take many forms; a group that is being biased against may be less likely to receive resources that it otherwise should be allocated--think jobs, government benefits, and housing, among other things. 

This toolkit is designed to help you identify, understand, and mitigate potential sources of bias in your data, algorithms, and processes. In its current form, this toolkit is targeted towards practitioners and managers with intermediate knowledge of data collection and AI/ML algorithms. The resources featured here are relevant to both technical teams and teams whose mission delivery could be impacted by certain tools, i.e. hiring managers seeking to reduce bias in their job applicant pools.

The existing tools were chosen based on existing needs that we identified across the federal government with our agency partners. We anticipate adding a wider variety of resources in the future. Want to partner with us or suggest an addition to the toolkit? Contact us at [inquiries@xd.gov](mailto:inquiries@xd.gov).